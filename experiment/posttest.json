{
  "version": 2.0,
  "questions": [
    {
      "question": "What is the purpose of the kernel trick in SVM?",
      "answers": {
        "a": "To reduce the dataset size",
        "b": "To simplify the SVM algorithm",
        "c": "To project data into higher dimensions for better separation",
        "d": "To eliminate irrelevant features"
      },
      "explanations": {
        "a": "Kernel trick doesn’t reduce data size; it increases feature complexity.",
        "b": "Kernel adds complexity to SVM, not simplification.",
        "c": "Correct!It helps handle non-linear data by mapping it to a higher-dimensional space.",
        "d": "Feature selection is a separate process, not handled by kernels."
      },
      "correctAnswer": "c",
      "difficulty": "beginner"
    },
    {
      "question": "Which metric is most important when evaluating a fraud detection model?",
      "answers": {
        "a": "Accuracy",
        "b": "Precision",
        "c": "Recall",
        "d": "F1-Score"
      },
      "explanations": {
        "a": "Accuracy can be misleading with imbalanced data.",
        "b": "Precision is important, but doesn't consider false negatives.",
        "c": "Recall matters, but may sacrifice precision.",
        "d": "Correct!F1-score balances both precision and recall — ideal for fraud detection."
      },
      "correctAnswer": "d",
      "difficulty": "beginner"
    },
    {
      "question": "What does a high regularization parameter (C) in SVM signify?",
      "answers": {
        "a": "A wider margin with more misclassifications",
        "b": "A simpler model with fewer support vectors",
        "c": "A narrower margin and fewer training errors",
        "d": "Removal of the kernel function"
      },
      "explanations": {
        "a": "Low C allows a wider margin with more errors.",
        "b": "High C increases complexity, not simplification.",
        "c": "Correct!High C focuses on classifying all training points correctly.",
        "d": "Kernel is unrelated to the C parameter."
      },
      "correctAnswer": "c",
      "difficulty": "beginner"
    },
    {
      "question": "In the context of SVM, what are support vectors?",
      "answers": {
        "a": "Outliers in the dataset",
        "b": "Points that define the decision boundary",
        "c": "The largest features in the dataset",
        "d": "Weights used to normalize data"
      },
      "explanations": {
        "a": "Outliers may or may not be support vectors.",
        "b": "Correct!Support vectors lie closest to the margin and influence the hyperplane.",
        "c": "Features and support vectors are unrelated concepts.",
        "d": "Data normalization is done separately before model training."
      },
      "correctAnswer": "b",
      "difficulty": "beginner"
    },
    {
      "question": "Why is RBF kernel often preferred in fraud detection over linear kernel?",
      "answers": {
        "a": "It is faster in computation",
        "b": "It doesn’t require preprocessing",
        "c": "It captures complex, non-linear relationships",
        "d": "It increases dataset size"
      },
      "explanations": {
        "a": "RBF is more computationally intensive than linear.",
        "b": "SVM still requires preprocessing like normalization.",
        "c": "Correct!RBF can handle complex boundaries between classes effectively.",
        "d": "It doesn’t change dataset size, just feature space mapping."
      },
      "correctAnswer": "c",
      "difficulty": "beginner"
    }
  ]
}
